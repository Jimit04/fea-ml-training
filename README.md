# FEA Reduced-Order Model (ROM)

A proof-of-concept that uses **Machine Learning to replace expensive FEA solvers**.
A neural network is trained on data generated from Euler-Bernoulli beam theory, then used to predict full displacement and stress fields in milliseconds.

> ğŸ“„ See [docs/Overview.md](docs/Overview.md) for detailed explanation of the physics, architecture, and training strategy.

---

## Workflow

1. **Data Generation** â€” `MockFEASolver` analytically solves a cantilever beam using Euler-Bernoulli beam theory (Steel: E=210,000 MPa, Î½=0.29). Outputs displacement and stress fields on a 21Ã—6Ã—6 hex mesh.
2. **Training** â€” A TensorFlow/Keras neural network (MLP or GCN) learns the mapping from `[Length, Width, Depth, Load]` â†’ full field results.
3. **Visualisation** â€” PyVista renders GT vs Predicted side-by-side with max values and % errors.

---

## Setup

Project is managed with `uv`.

```bash
uv sync
```

---

## Usage

```bash
# Full pipeline (generate â†’ train â†’ visualize)
uv run .\main.py

# Generate 500 samples
uv run .\main.py --generate --samples 500

# Train with MLP (default)
uv run .\main.py --train --model mlp

# Train with GCN
uv run .\main.py --train --model gcn

# Visualize predictions vs ground truth
uv run .\main.py --visualize

# Save visualization to file
uv run .\main.py --visualize --screenshot output.png
```

### Arguments

| Argument | Description | Default |
|----------|-------------|---------|
| `--generate` | Generate synthetic dataset | â€” |
| `--train` | Train the ROM model | â€” |
| `--visualize` | Launch 3D visualizer | â€” |
| `--samples N` | Number of samples to generate | 500 |
| `--model` | Model type: `mlp` or `gcn` | `mlp` |
| `--screenshot PATH` | Save screenshot instead of opening window | â€” |

---

## Models

### MLP (Multi-Layer Perceptron)
Deep Dense network: `4 â†’ 256 â†’ 512 â†’ 512 â†’ 256 â†’ output`
- Swish activations, BatchNorm, Dropout
- ~723,700 parameters

### GCN (Graph Convolutional Network)
Treats the beam mesh as a graph. Performs spectral convolution over the 21Ã—6Ã—6 node adjacency.
- 3 GCN layers (64 â†’ 128 â†’ 64), global average pool, Dense decoder head
- ~554,900 parameters

---

## Inputs & Physics

| Parameter | Symbol | Unit | Range |
|-----------|--------|------|-------|
| Length | L | mm | 5 â€“ 20 |
| Width  | w | mm | 0.5 â€“ 3 |
| Depth  | d | mm | 0.1 â€“ 0.5 |
| Load   | P | N  | 1,000 â€“ 50,000 |

**Material:** Steel â€” E = 210,000 MPa, Î½ = 0.29

---

## Project Structure

```
fea-ml-training/
â”œâ”€â”€ main.py                    â† CLI entry point
â”œâ”€â”€ DOCUMENTATION.md           â† Detailed documentation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_generator.py      â† MockFEASolver (Euler-Bernoulli physics)
â”‚   â”œâ”€â”€ generate_dataset.py    â† Batch sample generation
â”‚   â”œâ”€â”€ rom_model.py           â† GCNLayer, MLP/GCN builders, ROMTrainer
â”‚   â””â”€â”€ visualizer.py          â† PyVista 3D visualizer
â”œâ”€â”€ mock_data/                 â† Generated .npy and .vtk samples
â””â”€â”€ models/                    â† Saved .keras models and .npy scalers
```
